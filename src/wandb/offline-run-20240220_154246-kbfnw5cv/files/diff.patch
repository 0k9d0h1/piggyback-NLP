diff --git a/src/__pycache__/dataset.cpython-310.pyc b/src/__pycache__/dataset.cpython-310.pyc
index 1c2d780..0b37b29 100644
Binary files a/src/__pycache__/dataset.cpython-310.pyc and b/src/__pycache__/dataset.cpython-310.pyc differ
diff --git a/src/asdf.py b/src/asdf.py
index 40e61c5..683937a 100644
--- a/src/asdf.py
+++ b/src/asdf.py
@@ -1,5 +1,65 @@
+import avalanche
 import torch
+import itertools
+import pandas as pd
+import random
+import json
+import jsonlines
+import xml.etree.ElementTree as ET
+import argparse
+import torch.nn as nn
+import avalanche.evaluation.metrics as amet
 
-a = torch.rand(2, 768, 512)
+from avalanche.benchmarks.generators import tensors_benchmark, dataset_benchmark
+from avalanche.training.templates import SupervisedTemplate
+from avalanche.logging import InteractiveLogger, WandBLogger
+from avalanche.training.plugins import EvaluationPlugin
+from transformers import BertModel
+from transformers import AutoTokenizer
+from transformers import BertConfig
+from modnets import BertForPreTraining
+from datasets import Dataset
+from torch.utils.data import TensorDataset
+from dataset import create_unlabeled_benchmark, create_endtask_benchmark
+from dataset_small import create_small_benchmark
+from typing import Any, Callable, Dict, Iterable, List, NamedTuple, Optional, Sequence, Union
+import multiprocessing
+# torch.set_printoptions(profile="full")
 
-print(a[:, None, :, :].shape)
+FLAGS = argparse.ArgumentParser()
+FLAGS.add_argument('--datasets', type=str, default='s2orc,realnews,pubmed',
+                   help='Names of datasets')
+FLAGS.add_argument('--model', type=str, default='bert-base-uncased',
+                   help='type of pretrained model')
+FLAGS.add_argument('--epoch', type=int, default=5)
+FLAGS.add_argument('--seed', type=int, default=1)
+args = FLAGS.parse_args()
+
+tokenizer = AutoTokenizer.from_pretrained(args.model)
+
+# benchmark_endtask = create_endtask_benchmark(args, tokenizer)
+# train_stream = benchmark_endtask.train_stream
+# test_stream = benchmark_endtask.test_stream
+# val_stream = benchmark_endtask.stream_factory("val", benchmark_endtask)
+# for train_exp, test_exp, val_exp in zip(train_stream, test_stream, val_stream):
+#     print(len(train_exp.dataset))
+#     print(tokenizer.decode(
+#         train_exp.dataset[0][0][0].type(torch.IntTensor).tolist()))
+
+# benchmark_unlabeled = create_unlabeled_benchmark(args, tokenizer)
+# train_stream = benchmark_unlabeled.train_stream
+# test_stream = benchmark_unlabeled.test_stream
+# val_stream = benchmark_unlabeled.stream_factory("val", benchmark_unlabeled)
+# for train_exp, test_exp, val_exp in zip(train_stream, test_stream, val_stream):
+#     print(len(train_exp.dataset))
+#     print(train_exp.dataset[0])
+#     print(test_exp.dataset[0])
+#     print(val_exp.dataset[0])
+
+benchmark_small = create_small_benchmark(args, tokenizer)
+train_stream = benchmark_small.train_stream
+test_stream = benchmark_small.test_stream
+val_stream = benchmark_small.stream_factory("val", benchmark_small)
+for train_exp, test_exp, val_exp in zip(train_stream, test_stream, val_stream):
+    print(len(train_exp.dataset))
+    print(train_exp.dataset[0])
diff --git a/src/dataset.py b/src/dataset.py
index f803844..b87c2f3 100644
--- a/src/dataset.py
+++ b/src/dataset.py
@@ -16,7 +16,7 @@ MASK_PROP = 0.15
 def get_nsp_data(tokenizer, paragraphs):
     label = []
     nsp_data = []
-    for paragraph in paragraphs:
+    for paragraph in tqdm(paragraphs):
         for i in range(len(paragraph) - 1):
             if random.random() < 0.5:
                 label.append(1)
@@ -32,8 +32,10 @@ def get_nsp_data(tokenizer, paragraphs):
 
 def mask_nsp_data(tokenizer, paragraphs):
     nsp_data, label = get_nsp_data(tokenizer, paragraphs)
+    original_input_ids = torch.stack(
+        [torch.Tensor(a['input_ids']) for a in nsp_data])
 
-    for i, tokens in enumerate(nsp_data):
+    for i, tokens in tqdm(enumerate(nsp_data)):
         for j, token in enumerate(tokens['input_ids']):
             if token != 0 and token != 101 and token != 102:
                 if random.random() < MASK_PROP:
@@ -41,31 +43,35 @@ def mask_nsp_data(tokenizer, paragraphs):
                         nsp_data[i]['input_ids'][j] = 103
                     else:
                         if random.random() < 0.5:
-                            nsp_data[i]['input_ids'][j] = random.randint(
-                                1, len(tokenizer.get_vocab()))
-    return nsp_data, label
+                            r = random.randint(
+                                1000, len(tokenizer.get_vocab()) - 1)
+                            nsp_data[i]['input_ids'][j] = r
+    return nsp_data, original_input_ids, label
 
 
 def get_paragraphs(data):
     paragraphs = []
     if data == 'realnews':
+        i = 0
         with jsonlines.open('../data/unlabeled/realnews/realnews.jsonl') as f:
-            for i, lin in enumerate(f):
+            for lin in tqdm(f):
                 sentences = lin['text'].strip().replace(
                     '\n', '').lower().split('. ')
                 paragraph = []
                 for sentence in sentences:
                     if len(sentence) >= 2:
                         paragraph.append(sentence)
+                        i += 1
                 if len(paragraph) != 0:
                     paragraphs.append(paragraph)
-                if i == 2:
+
+                if i > 600000:
                     break
 
     elif data == 'pubmed':
         pubmed = load_dataset('pubmed', streaming=True, trust_remote_code=True)
         i = 0
-        for entry in pubmed['train']:
+        for entry in tqdm(pubmed['train']):
             abstracttext = entry['MedlineCitation']['Article']['Abstract']['AbstractText']
             sentences = abstracttext.strip().replace('\n', '').lower().split('. ')
             paragraph = []
@@ -75,12 +81,13 @@ def get_paragraphs(data):
                     i += 1
             if len(paragraph) != 0:
                 paragraphs.append(paragraph)
-            if i > 10:
+
+            if i > 600000:
                 break
 
     elif data == 's2orc':
         file_list = os.listdir('../data/unlabeled/s2orc')
-        for file in file_list:
+        for file in tqdm(file_list):
             with jsonlines.open('../data/unlabeled/s2orc/%s' % file) as f:
                 i = 0
                 for lin in f:
@@ -94,8 +101,6 @@ def get_paragraphs(data):
                                 paragraph.append(sentence)
                         if len(paragraph) != 0:
                             paragraphs.append(paragraph)
-                        if i == 2:
-                            break
     return paragraphs
 
 
@@ -103,267 +108,286 @@ def create_unlabeled_benchmark(args, tokenizer):
     dat = args.datasets.split(',')
     train_datasets = []
     test_datasets = []
+    val_datasets = []
 
     for task_label, dataset in enumerate(dat):
-        paragraphs = get_paragraphs(dataset)
-        nsp_data, label = mask_nsp_data(tokenizer, paragraphs)
+        path = "../datasets/%s/unlabeled" % (dataset)
+        dir = os.listdir(path)
+        if len(dir) == 0:
+            paragraphs = get_paragraphs(dataset)
+            nsp_data, original_input_ids, label = mask_nsp_data(
+                tokenizer, paragraphs)
+
+            input_ids = torch.stack(
+                [torch.Tensor(a['input_ids']).type(torch.IntTensor) for a in nsp_data])
+            token_type_ids = torch.stack(
+                [torch.Tensor(a['token_type_ids']).type(torch.IntTensor) for a in nsp_data])
+            attention_mask = torch.stack(
+                [torch.Tensor(a['attention_mask']).type(torch.IntTensor) for a in nsp_data])
+            label = torch.Tensor(label)
+            length = label.shape[0]
+
+            nsp_data = torch.stack(
+                [input_ids, original_input_ids, token_type_ids, attention_mask], dim=1)
+
+            idx = torch.randperm(length)
+            nsp_data = nsp_data[idx].view(nsp_data.size())
+            label = label[idx].view(label.size())
+
+            train_dataset = TensorDataset(
+                nsp_data[:int(length * 4 / 5)], label[:int(length * 4 / 5)])
+            val_dataset = TensorDataset(nsp_data[int(
+                length * 4 / 5):int(length * 9 / 10)], label[int(length * 4 / 5):int(length * 9 / 10)])
+            test_dataset = TensorDataset(
+                nsp_data[int(length * 9 / 10):], label[int(length * 9 / 10):])
+
+            torch.save(train_dataset, "%s/train.pt" % (path))
+            torch.save(val_dataset, "%s/val.pt" % (path))
+            torch.save(test_dataset, "%s/test.pt" % (path))
+
+        else:
+            train_dataset = torch.load("%s/train.pt" % (path))
+            val_dataset = torch.load("%s/val.pt" % (path))
+            test_dataset = torch.load("%s/test.pt" % (path))
+
+        train_dataset_with_task_label = make_classification_dataset(
+            train_dataset, task_labels=task_label)
+        val_dataset_with_task_label = make_classification_dataset(
+            val_dataset, task_labels=task_label)
+        test_dataset_with_task_label = make_classification_dataset(
+            test_dataset, task_labels=task_label)
+
+        train_datasets.append(train_dataset_with_task_label)
+        val_datasets.append(val_dataset_with_task_label)
+        test_datasets.append(test_dataset_with_task_label)
+
+    return dataset_benchmark(train_datasets, test_datasets, other_streams_datasets={"val": val_datasets})
+
+
+def preprocess_hyperpartisan(lin, tokenizer):
+    text = re.sub('<[^>]+>', '', lin['text'])
+    index = text.find('&#')
+    text = text.replace("..", "")
+    while index > -1:
+        idx_semicolon = index + 2
+        if index + 2 < len(text) and text[index+2].isdigit():
+            while idx_semicolon < len(text) and text[idx_semicolon] != ';':
+                idx_semicolon += 1
+                if index - idx_semicolon > 6:
+                    break
+            if text[index+2:idx_semicolon].isdigit():
+                unicode_decimal = int(text[index+2:idx_semicolon])
+                unicode = f'&#%d;' % unicode_decimal
+                text = text.replace(unicode,
+                                    chr(unicode_decimal))
+        index = text.find('&#')
+    text = text.replace("&amp;#160", " ")
+    text = text.replace("&amp;amp;", "&")
+    text = text.replace("&amp;gt;", ">")
+
+    tokens = tokenizer(text, padding='max_length',
+                       max_length=512, truncation='longest_first')
+    input_ids = torch.Tensor(tokens['input_ids'])
+    token_type_ids = torch.Tensor(tokens['token_type_ids'])
+    attention_mask = torch.Tensor(tokens['attention_mask'])
 
-        input_ids = torch.stack(
-            [torch.Tensor(a['input_ids']) for a in nsp_data])
-        token_type_ids = torch.stack(
-            [torch.Tensor(a['token_type_ids']) for a in nsp_data])
-        attention_mask = torch.stack(
-            [torch.Tensor(a['attention_mask']) for a in nsp_data])
-        label = torch.Tensor(label)
-        length = label.shape[0]
+    nsp_data = torch.stack(
+        [input_ids, token_type_ids, attention_mask], dim=0)
 
-        nsp_data = torch.stack(
-            [input_ids, token_type_ids, attention_mask], dim=1)
+    return nsp_data
 
-        idx = torch.randperm(length)
-        nsp_data = nsp_data[idx].view(nsp_data.size())
-        label = label[idx].view(label.size())
 
-        train_datasets.append(make_classification_dataset(
-            TensorDataset(nsp_data[:int(length * 4 / 5)], label[:int(length * 4 / 5)]), task_labels=task_label))
-        test_datasets.append(make_classification_dataset(
-            TensorDataset(nsp_data[int(length * 4 / 5):], label[int(length * 4 / 5):]), task_labels=task_label))
+def preprocess(lin, tokenizer):
+    tokens = tokenizer(lin['text'], padding='max_length',
+                       max_length=512, truncation='longest_first')
+    input_ids = torch.Tensor(tokens['input_ids'])
+    token_type_ids = torch.Tensor(tokens['token_type_ids'])
+    attention_mask = torch.Tensor(tokens['attention_mask'])
 
-    return dataset_benchmark(train_datasets, test_datasets)
+    nsp_data = torch.stack(
+        [input_ids, token_type_ids, attention_mask], dim=0)
+
+    return nsp_data
 
 
 def create_endtask_benchmark(args, tokenizer):
     dat = args.datasets.split(',')
     train_datasets = []
     test_datasets = []
+    val_datasets = []
 
     for task_label, dataset in enumerate(dat):
+        path = "../datasets/%s/endtask" % (dataset)
+        dir = os.listdir(path)
         if dataset == 'realnews':
-            hyperpartisan = load_dataset('hyperpartisan_news_detection', 'bypublisher',
-                                         trust_remote_code=True)
-            str_to_idx = {'false': 0,
-                          'true': 1}
-
-            label_train = []
-            input_train = []
-            for i, lin in enumerate(hyperpartisan['train']):
-                text = re.sub('<[^>]+>', '', lin['text'])
-                index = text.find('&#')
-                text = text.replace("..", "")
-                while index > -1:
-                    idx_semicolon = index + 2
-                    if index + 2 < len(text) and text[index+2].isdigit():
-                        while idx_semicolon < len(text) and text[idx_semicolon] != ';':
-                            idx_semicolon += 1
-                            if index - idx_semicolon > 6:
-                                break
-                        if text[index+2:idx_semicolon].isdigit():
-                            unicode_decimal = int(text[index+2:idx_semicolon])
-                            unicode = f'&#%d;' % unicode_decimal
-                            text = text.replace(unicode,
-                                                chr(unicode_decimal))
-                    index = text.find('&#')
-                text = text.replace("&amp;#160", " ")
-                text = text.replace("&amp;amp;", "&")
-                text = text.replace("&amp;gt;", ">")
-
-                label_train.append(int(lin['hyperpartisan']))
-
-                tokens = tokenizer(text, padding='max_length',
-                                   max_length=512, truncation='longest_first')
-                input_ids = torch.Tensor(tokens['input_ids'])
-                token_type_ids = torch.Tensor(tokens['token_type_ids'])
-                attention_mask = torch.Tensor(tokens['attention_mask'])
-
-                nsp_data = torch.stack(
-                    [input_ids, token_type_ids, attention_mask], dim=0)
-                input_train.append(nsp_data)
-
-                if i == 20:
-                    break
-
-            label_train = torch.Tensor(label_train)
-            input_train = torch.stack(input_train)
-
-            label_test = []
-            input_test = []
-            for i, lin in enumerate(hyperpartisan['validation']):
-                text = re.sub('<[^>]+>', '', lin['text'])
-                index = text.find('&#')
-                text = text.replace("..", "")
-                while index > -1:
-                    idx_semicolon = index + 2
-                    if index + 2 < len(text) and text[index+2].isdigit():
-                        while idx_semicolon < len(text) and text[idx_semicolon] != ';':
-                            idx_semicolon += 1
-                            if index - idx_semicolon > 6:
-                                break
-                        if text[index+2:idx_semicolon].isdigit():
-                            unicode_decimal = int(text[index+2:idx_semicolon])
-                            unicode = f'&#%d;' % unicode_decimal
-                            text = text.replace(unicode,
-                                                chr(unicode_decimal))
-                    index = text.find('&#')
-                text = text.replace("&amp;#160", " ")
-                text = text.replace("&amp;amp;", "&")
-                text = text.replace("&amp;gt;", ">")
-
-                label_test.append(int(lin['hyperpartisan']))
-                tokens = tokenizer(text, padding='max_length',
-                                   max_length=512, truncation='longest_first')
-                input_ids = torch.Tensor(tokens['input_ids'])
-                token_type_ids = torch.Tensor(tokens['token_type_ids'])
-                attention_mask = torch.Tensor(tokens['attention_mask'])
-
-                nsp_data = torch.stack(
-                    [input_ids, token_type_ids, attention_mask], dim=0)
-                input_test.append(nsp_data)
-
-                if i == 5:
-                    break
-
-            label_test = torch.Tensor(label_test)
-            input_test = torch.stack(input_test)
-
-            train_datasets.append(make_classification_dataset(
-                TensorDataset(input_train, label_train), task_labels=task_label))
-            test_datasets.append(make_classification_dataset(
-                TensorDataset(input_test, label_test), task_labels=task_label))
-
-        elif dataset == 'pubmed':
-            str_to_idx = {'INHIBITOR': 0,
-                          'ANTAGONIST': 1,
-                          'AGONIST': 2,
-                          'DOWNREGULATOR': 3,
-                          'PRODUCT-OF': 4,
-                          'SUBSTRATE': 5,
-                          'INDIRECT-UPREGULATOR': 6,
-                          'UPREGULATOR': 7,
-                          'INDIRECT-DOWNREGULATOR': 8,
-                          'ACTIVATOR': 9,
-                          'AGONIST-ACTIVATOR': 10,
-                          'AGONIST-INHIBITOR': 11,
-                          'SUBSTRATE_PRODUCT-OF': 12
-                          }
-            label_train = []
-            input_train = []
-            with jsonlines.open('../data/endtask/chemprot/train.txt') as f:
-                for lin in f:
-                    label_train.append(str_to_idx[lin['label']])
-
-                    tokens = tokenizer(lin['text'], padding='max_length',
-                                       max_length=512, truncation='longest_first')
-                    input_ids = torch.Tensor(tokens['input_ids'])
-                    token_type_ids = torch.Tensor(tokens['token_type_ids'])
-                    attention_mask = torch.Tensor(tokens['attention_mask'])
-
-                    nsp_data = torch.stack(
-                        [input_ids, token_type_ids, attention_mask], dim=0)
-                    input_train.append(nsp_data)
-            with jsonlines.open('../data/endtask/chemprot/dev.txt') as f:
-                for lin in f:
-                    label_train.append(str_to_idx[lin['label']])
-
-                    tokens = tokenizer(lin['text'], padding='max_length',
-                                       max_length=512, truncation='longest_first')
-                    input_ids = torch.Tensor(tokens['input_ids'])
-                    token_type_ids = torch.Tensor(tokens['token_type_ids'])
-                    attention_mask = torch.Tensor(tokens['attention_mask'])
-
-                    nsp_data = torch.stack(
-                        [input_ids, token_type_ids, attention_mask], dim=0)
-                    input_train.append(nsp_data)
-
-            label_train = torch.Tensor(label_train)
-            input_train = torch.stack(input_train)
-
-            label_test = []
-            input_test = []
-
-            with jsonlines.open('../data/endtask/chemprot/test.txt') as f:
-                for lin in f:
-                    label_test.append(str_to_idx[lin['label']])
-
-                    tokens = tokenizer(lin['text'], padding='max_length',
-                                       max_length=512, truncation='longest_first')
-                    input_ids = torch.Tensor(tokens['input_ids'])
-                    token_type_ids = torch.Tensor(tokens['token_type_ids'])
-                    attention_mask = torch.Tensor(tokens['attention_mask'])
-
-                    nsp_data = torch.stack(
-                        [input_ids, token_type_ids, attention_mask], dim=0)
+            if len(dir) == 0:
+                hyperpartisan_train = load_dataset('hyperpartisan_news_detection', 'bypublisher',
+                                                   trust_remote_code=True, split='train')
+                hyperpartisan_test = load_dataset('hyperpartisan_news_detection', 'bypublisher',
+                                                  trust_remote_code=True, split='validation[0%:50%]')
+                hyperpartisan_val = load_dataset('hyperpartisan_news_detection', 'bypublisher',
+                                                 trust_remote_code=True, split='validation[50%:100%]')
+
+                label_test = []
+                input_test = []
+                for lin in tqdm(hyperpartisan_test):
+                    label_test.append(int(lin['hyperpartisan']))
+                    nsp_data = preprocess_hyperpartisan(lin, tokenizer)
                     input_test.append(nsp_data)
-
-            label_test = torch.Tensor(label_test)
-            input_test = torch.stack(input_test)
-
-            train_datasets.append(make_classification_dataset(
-                TensorDataset(input_train, label_train), task_labels=task_label))
-            test_datasets.append(make_classification_dataset(
-                TensorDataset(input_test, label_test), task_labels=task_label))
-
-        elif dataset == 's2orc':
-            str_to_idx = {'Background': 0,
-                          'Uses': 1,
-                          'CompareOrContrast': 2,
-                          'Extends': 3,
-                          'Motivation': 4,
-                          'Future': 5
-                          }
-            label_train = []
-            input_train = []
-            with jsonlines.open('../data/endtask/citation_intent/train.txt') as f:
-                for lin in f:
-                    label_train.append(str_to_idx[lin['label']])
-
-                    tokens = tokenizer(lin['text'], padding='max_length',
-                                       max_length=512, truncation='longest_first')
-                    input_ids = torch.Tensor(tokens['input_ids'])
-                    token_type_ids = torch.Tensor(tokens['token_type_ids'])
-                    attention_mask = torch.Tensor(tokens['attention_mask'])
-
-                    nsp_data = torch.stack(
-                        [input_ids, token_type_ids, attention_mask], dim=0)
-                    input_train.append(nsp_data)
-            with jsonlines.open('../data/endtask/citation_intent/dev.txt') as f:
-                for lin in f:
-                    label_train.append(str_to_idx[lin['label']])
-
-                    tokens = tokenizer(lin['text'], padding='max_length',
-                                       max_length=512, truncation='longest_first')
-                    input_ids = torch.Tensor(tokens['input_ids'])
-                    token_type_ids = torch.Tensor(tokens['token_type_ids'])
-                    attention_mask = torch.Tensor(tokens['attention_mask'])
-
-                    nsp_data = torch.stack(
-                        [input_ids, token_type_ids, attention_mask], dim=0)
+                label_test = torch.Tensor(label_test)
+                input_test = torch.stack(input_test)
+
+                label_train = []
+                input_train = []
+                for lin in tqdm(hyperpartisan_train):
+                    label_train.append(int(lin['hyperpartisan']))
+                    nsp_data = preprocess_hyperpartisan(lin, tokenizer)
                     input_train.append(nsp_data)
+                label_train = torch.Tensor(label_train)
+                input_train = torch.stack(input_train)
+
+                label_val = []
+                input_val = []
+                for lin in tqdm(hyperpartisan_val):
+                    label_val.append(int(lin['hyperpartisan']))
+                    nsp_data = preprocess_hyperpartisan(lin, tokenizer)
+                    input_val.append(nsp_data)
+                label_val = torch.Tensor(label_val)
+                input_val = torch.stack(input_val)
+
+                train_dataset = TensorDataset(input_train, label_train)
+                test_dataset = TensorDataset(input_test, label_test)
+                val_dataset = TensorDataset(input_val, label_val)
+
+                torch.save(train_dataset, "%s/train.pt" % (path))
+                torch.save(val_dataset, "%s/val.pt" % (path))
+                torch.save(test_dataset, "%s/test.pt" % (path))
 
-            label_train = torch.Tensor(label_train)
-            input_train = torch.stack(input_train)
-
-            label_test = []
-            input_test = []
-            with jsonlines.open('../data/endtask/citation_intent/test.txt') as f:
-                for lin in f:
-                    label_test.append(str_to_idx[lin['label']])
-
-                    tokens = tokenizer(lin['text'], padding='max_length',
-                                       max_length=512, truncation='longest_first')
-                    input_ids = torch.Tensor(tokens['input_ids'])
-                    token_type_ids = torch.Tensor(tokens['token_type_ids'])
-                    attention_mask = torch.Tensor(tokens['attention_mask'])
+            else:
+                train_dataset = torch.load("%s/train.pt" % (path))
+                val_dataset = torch.load("%s/val.pt" % (path))
+                test_dataset = torch.load("%s/test.pt" % (path))
 
-                    nsp_data = torch.stack(
-                        [input_ids, token_type_ids, attention_mask], dim=0)
-                    input_test.append(nsp_data)
+        elif dataset == 'pubmed':
+            if len(dir) == 0:
+                str_to_idx = {'INHIBITOR': 0,
+                              'ANTAGONIST': 1,
+                              'AGONIST': 2,
+                              'DOWNREGULATOR': 3,
+                              'PRODUCT-OF': 4,
+                              'SUBSTRATE': 5,
+                              'INDIRECT-UPREGULATOR': 6,
+                              'UPREGULATOR': 7,
+                              'INDIRECT-DOWNREGULATOR': 8,
+                              'ACTIVATOR': 9,
+                              'AGONIST-ACTIVATOR': 10,
+                              'AGONIST-INHIBITOR': 11,
+                              'SUBSTRATE_PRODUCT-OF': 12
+                              }
+                label_train = []
+                input_train = []
+                with jsonlines.open('../data/endtask/chemprot/train.txt') as f:
+                    for lin in tqdm(f):
+                        label_train.append(str_to_idx[lin['label']])
+                        nsp_data = preprocess(lin, tokenizer)
+                        input_train.append(nsp_data)
+                label_train = torch.Tensor(label_train)
+                input_train = torch.stack(input_train)
+
+                label_val = []
+                input_val = []
+                with jsonlines.open('../data/endtask/chemprot/dev.txt') as f:
+                    for lin in tqdm(f):
+                        label_val.append(str_to_idx[lin['label']])
+                        nsp_data = preprocess(lin, tokenizer)
+                        input_val.append(nsp_data)
+                label_val = torch.Tensor(label_val)
+                input_val = torch.stack(input_val)
+
+                label_test = []
+                input_test = []
+                with jsonlines.open('../data/endtask/chemprot/test.txt') as f:
+                    for lin in tqdm(f):
+                        label_test.append(str_to_idx[lin['label']])
+                        nsp_data = preprocess(lin, tokenizer)
+                        input_test.append(nsp_data)
+                label_test = torch.Tensor(label_test)
+                input_test = torch.stack(input_test)
+
+                train_dataset = TensorDataset(input_train, label_train)
+                test_dataset = TensorDataset(input_test, label_test)
+                val_dataset = TensorDataset(input_val, label_val)
+
+                torch.save(train_dataset, "%s/train.pt" % (path))
+                torch.save(val_dataset, "%s/val.pt" % (path))
+                torch.save(test_dataset, "%s/test.pt" % (path))
 
-            label_test = torch.Tensor(label_test)
-            input_test = torch.stack(input_test)
+            else:
+                train_dataset = torch.load("%s/train.pt" % (path))
+                val_dataset = torch.load("%s/val.pt" % (path))
+                test_dataset = torch.load("%s/test.pt" % (path))
 
-            train_datasets.append(make_classification_dataset(
-                TensorDataset(input_train, label_train), task_labels=task_label))
-            test_datasets.append(make_classification_dataset(
-                TensorDataset(input_test, label_test), task_labels=task_label))
+        elif dataset == 's2orc':
+            if len(dir) == 0:
+                str_to_idx = {'Background': 0,
+                              'Uses': 1,
+                              'CompareOrContrast': 2,
+                              'Extends': 3,
+                              'Motivation': 4,
+                              'Future': 5
+                              }
+                label_train = []
+                input_train = []
+                with jsonlines.open('../data/endtask/citation_intent/train.txt') as f:
+                    for lin in tqdm(f):
+                        label_train.append(str_to_idx[lin['label']])
+                        nsp_data = preprocess(lin, tokenizer)
+                        input_train.append(nsp_data)
+                label_train = torch.Tensor(label_train)
+                input_train = torch.stack(input_train)
+
+                label_val = []
+                input_val = []
+                with jsonlines.open('../data/endtask/citation_intent/dev.txt') as f:
+                    for lin in tqdm(f):
+                        label_val.append(str_to_idx[lin['label']])
+                        nsp_data = preprocess(lin, tokenizer)
+                        input_val.append(nsp_data)
+                label_val = torch.Tensor(label_val)
+                input_val = torch.stack(input_val)
+
+                label_test = []
+                input_test = []
+                with jsonlines.open('../data/endtask/citation_intent/test.txt') as f:
+                    for lin in tqdm(f):
+                        label_test.append(str_to_idx[lin['label']])
+                        nsp_data = preprocess(lin, tokenizer)
+                        input_test.append(nsp_data)
+                label_test = torch.Tensor(label_test)
+                input_test = torch.stack(input_test)
+
+                train_dataset = TensorDataset(input_train, label_train)
+                test_dataset = TensorDataset(input_test, label_test)
+                val_dataset = TensorDataset(input_val, label_val)
+
+                torch.save(train_dataset, "%s/train.pt" % (path))
+                torch.save(val_dataset, "%s/val.pt" % (path))
+                torch.save(test_dataset, "%s/test.pt" % (path))
 
-    return dataset_benchmark(train_datasets, test_datasets)
+            else:
+                train_dataset = torch.load("%s/train.pt" % (path))
+                val_dataset = torch.load("%s/val.pt" % (path))
+                test_dataset = torch.load("%s/test.pt" % (path))
+
+        train_dataset_with_task_label = make_classification_dataset(
+            train_dataset, task_labels=task_label)
+        test_dataset_with_task_label = make_classification_dataset(
+            test_dataset, task_labels=task_label)
+        val_dataset_with_task_label = make_classification_dataset(
+            val_dataset, task_labels=task_label)
+
+        train_datasets.append(train_dataset_with_task_label)
+        val_datasets.append(val_dataset_with_task_label)
+        test_datasets.append(test_dataset_with_task_label)
+
+    return dataset_benchmark(train_datasets, test_datasets, other_streams_datasets={"val": val_datasets})
diff --git a/src/modnets/__pycache__/bert.cpython-310.pyc b/src/modnets/__pycache__/bert.cpython-310.pyc
index 2ac5771..a58dc8d 100644
Binary files a/src/modnets/__pycache__/bert.cpython-310.pyc and b/src/modnets/__pycache__/bert.cpython-310.pyc differ
diff --git a/src/modnets/bert.py b/src/modnets/bert.py
index 4b2582a..e1b1925 100644
--- a/src/modnets/bert.py
+++ b/src/modnets/bert.py
@@ -165,7 +165,6 @@ class BertSelfAttention(am.MultiTaskModule):
         past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,
         output_attentions: Optional[bool] = False,
     ) -> Tuple[torch.Tensor]:
-        print(hidden_states, task_label)
         mixed_query_layer = self.query(hidden_states, task_label)
 
         # If this is instantiated as a cross-attention module, the keys
@@ -202,7 +201,6 @@ class BertSelfAttention(am.MultiTaskModule):
         use_cache = past_key_value is not None
         if self.is_decoder:
             past_key_value = (key_layer, value_layer)
-
         # Take the dot product between "query" and "key" to get the raw attention scores.
         attention_scores = torch.matmul(
             query_layer, key_layer.transpose(-1, -2))
@@ -212,7 +210,6 @@ class BertSelfAttention(am.MultiTaskModule):
         if attention_mask is not None:
             # Apply the attention mask is (precomputed for all layers in BertModel forward() function)
             attention_scores = attention_scores + attention_mask
-        print(attention_scores.shape, attention_mask)
 
         # Normalize the attention scores to probabilities.
         attention_probs = nn.functional.softmax(attention_scores, dim=-1)
@@ -406,6 +403,7 @@ class BertLayer(am.MultiTaskModule):
         # decoder uni-directional self-attention cached key/values tuple is at positions 1,2
         self_attn_past_key_value = past_key_value[:
                                                   2] if past_key_value is not None else None
+
         self_attention_outputs = self.attention(
             hidden_states,
             attention_mask,
@@ -482,7 +480,6 @@ class BertEncoder(am.MultiTaskModule):
 
             layer_head_mask = head_mask[i] if head_mask is not None else None
             past_key_value = past_key_values[i] if past_key_values is not None else None
-
             layer_outputs = layer_module(
                 hidden_states,
                 attention_mask,
@@ -493,7 +490,6 @@ class BertEncoder(am.MultiTaskModule):
                 past_key_value,
                 output_attentions,
             )
-
             hidden_states = layer_outputs[0]
             if use_cache:
                 next_decoder_cache += (layer_outputs[-1],)
@@ -757,7 +753,6 @@ class BertModel(am.MultiTaskModule):
             inputs_embeds=inputs_embeds,
             past_key_values_length=past_key_values_length,
         )
-
         encoder_outputs = self.encoder(
             embedding_output,
             attention_mask=extended_attention_mask,
@@ -829,7 +824,6 @@ class BertForPreTraining(am.MultiTaskModule):
         output_hidden_states: Optional[bool] = None,
         return_dict: Optional[bool] = None,
     ):
-        print("!!!!", task_label)
         outputs = self.bert(
             input_ids,
             attention_mask=attention_mask,
@@ -848,3 +842,64 @@ class BertForPreTraining(am.MultiTaskModule):
             sequence_output, pooled_output, task_label)
 
         return prediction_scores, seq_relationship_score
+
+
+class BertForEndtask(am.MultiTaskModule):
+
+    def __init__(self, config, num_classes, mask_embedding=False):
+        super().__init__()
+        self.bert = BertModel(config, mask_embedding)
+        self.cls = MultiTaskClassifier(config.hidden_size, num_classes)
+
+    def adaptation(self, experience: CLExperience):
+        super().adaptation(experience)
+        for module in self.modules():
+            if 'adaptation' in dir(module) and module is not self:
+                module.adaptation(experience)
+
+    def forward(
+        self,
+        input_ids: Optional[torch.Tensor],
+        attention_mask: Optional[torch.Tensor],
+        token_type_ids: Optional[torch.Tensor],
+        task_label,
+        position_ids: Optional[torch.Tensor] = None,
+        head_mask: Optional[torch.Tensor] = None,
+        inputs_embeds: Optional[torch.Tensor] = None,
+        output_attentions: Optional[bool] = None,
+        output_hidden_states: Optional[bool] = None,
+        return_dict: Optional[bool] = None,
+    ):
+        return self.forward_single_task(input_ids, attention_mask, token_type_ids, task_label, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
+
+    def forward_single_task(
+        self,
+        input_ids: Optional[torch.Tensor],
+        attention_mask: Optional[torch.Tensor],
+        token_type_ids: Optional[torch.Tensor],
+        task_label,
+        position_ids: Optional[torch.Tensor] = None,
+        head_mask: Optional[torch.Tensor] = None,
+        inputs_embeds: Optional[torch.Tensor] = None,
+        output_attentions: Optional[bool] = None,
+        output_hidden_states: Optional[bool] = None,
+        return_dict: Optional[bool] = None,
+    ):
+        outputs = self.bert(
+            input_ids,
+            attention_mask=attention_mask,
+            token_type_ids=token_type_ids,
+            position_ids=position_ids,
+            task_label=task_label,
+            head_mask=head_mask,
+            inputs_embeds=inputs_embeds,
+            output_attentions=output_attentions,
+            output_hidden_states=output_hidden_states,
+            return_dict=return_dict,
+        )
+
+        pooled_output = outputs[1]
+        output = self.cls(
+            pooled_output, task_label)
+
+        return output
diff --git a/src/temp.py b/src/temp.py
deleted file mode 100644
index 394c161..0000000
--- a/src/temp.py
+++ /dev/null
@@ -1,161 +0,0 @@
-import avalanche
-import torch
-import itertools
-import pandas as pd
-import random
-import jsonlines
-import xml.etree.ElementTree as ET
-import argparse
-import torch.nn as nn
-import avalanche.evaluation.metrics as amet
-
-from avalanche.benchmarks.generators import tensors_benchmark, dataset_benchmark
-from avalanche.training.templates import SupervisedTemplate
-from avalanche.logging import InteractiveLogger, WandBLogger
-from avalanche.training.plugins import EvaluationPlugin
-from transformers import BertModel
-from transformers import AutoTokenizer
-from transformers import BertConfig
-from modnets import BertForPreTraining
-from datasets import Dataset
-from torch.utils.data import TensorDataset
-from dataset import create_unlabeled_benchmark, create_endtask_benchmark
-from typing import Any, Callable, Dict, Iterable, List, NamedTuple, Optional, Sequence, Union
-
-FLAGS = argparse.ArgumentParser()
-FLAGS.add_argument('--datasets', type=str, default='s2orc',
-                   help='Names of datasets')
-FLAGS.add_argument('--model', type=str, default='bert-base-uncased',
-                   help='type of pretrained model')
-FLAGS.add_argument('--epoch', type=int, default=1)
-args = FLAGS.parse_args()
-
-
-class PiggybackStrategy(SupervisedTemplate):
-    def __init__(self, *args, **kwargs):
-        super().__init__(*args, **kwargs)
-
-    def train(self, experiences: Any | Iterable, eval_streams: Sequence[Any | Iterable] | None = None, **kwargs):
-        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)
-        return super().train(experiences, eval_streams, **kwargs)
-
-    def forward(self):
-        # input_ids = d[0, :]
-        # token_type_ids = d[1, :]
-        # attention_mask = d[2, :]
-        input_ids = self.mb_x[:, 0, :].type(torch.IntTensor).to('cuda')
-        token_type_ids = self.mb_x[:, 1, :].type(torch.IntTensor).to('cuda')
-        attention_mask = self.mb_x[:, 2, :].type(torch.IntTensor).to('cuda')
-        print(input_ids.shape, token_type_ids.shape,
-              attention_mask.shape, self.mb_task_id)
-        return self.model(input_ids, token_type_ids, attention_mask, self.mb_task_id)
-
-    def backward(self):
-        super().backward()
-
-        for module in self.model.modules():
-            if 'ElementWiseConv2d' in str(type(module)) or 'ElementWiseLinear' in str(type(module)):
-                abs_weights = module.weight.data.abs()
-                for i in range(len(module.masks)):
-                    if module.masks[str(i)].grad is not None:
-                        module.masks[str(i)].grad.data.div_(abs_weights.mean())
-
-            elif 'ElementWiseMultiheadAttention' in str(type(module)):
-                if not module._qkv_same_embed_dim:
-                    abs_q_proj_weights = module.q_proj_weight.data.abs()
-                    abs_k_proj_weights = module.k_proj_weight.data.abs()
-                    abs_v_proj_weights = module.v_proj_weight.data.abs()
-                    for i in range(len(module.masks)):
-                        if module.masks[str(i)][0].grad is not None:
-                            module.masks[str(i)][0].grad.data.div_(
-                                abs_q_proj_weights.mean())
-                            module.masks[str(i)][1].grad.data.div_(
-                                abs_k_proj_weights.mean())
-                            module.masks[str(i)][2].grad.data.div_(
-                                abs_v_proj_weights.mean())
-                else:
-                    abs_in_proj_weights = module.in_proj_weight.data.abs()
-                    for i in range(len(module.masks)):
-                        if module.masks[str(i)].grad is not None:
-                            module.masks[str(i)].grad.data.div_(
-                                abs_in_proj_weights.mean())
-
-
-tokenizer = AutoTokenizer.from_pretrained(args.model)
-model_pretrained = BertModel.from_pretrained(args.model)
-
-if args.model == 'bert-base-uncased':
-    config = BertConfig()
-model = BertForPreTraining(config)
-
-criterion = nn.CrossEntropyLoss()
-optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
-
-interactive_logger = InteractiveLogger()
-# wandb_logger = WandBLogger(
-#     project_name="piggyback_ViT",
-#     run_name="piggyback_%s" % (args.datasets),
-#     path="../checkpoint",
-#     config=vars(args)
-# )
-eval_plugin = EvaluationPlugin(
-    amet.accuracy_metrics(
-        epoch=True,
-        experience=True,
-        stream=True
-    ),
-    amet.loss_metrics(
-        epoch=True,
-        experience=True,
-        stream=True
-    ),
-    loggers=[interactive_logger]
-)
-cl_strategy = PiggybackStrategy(model,
-                                optimizer,
-                                criterion,
-                                train_mb_size=128,
-                                train_epochs=args.epoch,
-                                eval_mb_size=128,
-                                device='cuda',
-                                evaluator=eval_plugin,
-                                eval_every=1)
-
-# benchmark_endtask = create_endtask_benchmark(args, tokenizer)
-benchmark_unlabeled = create_unlabeled_benchmark(args, tokenizer)
-
-# train_stream = benchmark_endtask.train_stream
-# test_stream = benchmark_endtask.test_stream
-train_stream = benchmark_unlabeled.train_stream
-test_stream = benchmark_unlabeled.test_stream
-
-torch.set_printoptions(profile="full")
-
-results = []
-for train_exp, test_exp in zip(train_stream, test_stream):
-    # d = train_exp.dataset[0][0]
-    # task_label = train_exp.dataset[0][2]
-    # input_ids = d[0, :]
-    # token_type_ids = d[1, :]
-    # attention_mask = d[2, :]
-    # a, b = model(input_ids=input_ids[None, :].type(torch.IntTensor), token_type_ids=token_type_ids[None, :].type(torch.IntTensor),
-    #              attention_mask=attention_mask[None, :].type(torch.IntTensor), task_label=task_label)
-    # print(a.shape, b.shape)
-    # model.adaptation(train_exp)
-    print(model)
-    print("Start of experience: ", train_exp.current_experience)
-    print("Current Classes: ", train_exp.classes_in_this_experience)
-
-    cl_strategy.train(train_exp, eval_streams=[test_exp])
-    print('Training completed')
-
-    # check(model, model_pretrained)
-
-    print('Computing accuracy on the test set')
-    result = cl_strategy.eval(test_stream)
-
-    results.append(result)
-# print(model)
-
-
-# self.mbatch
